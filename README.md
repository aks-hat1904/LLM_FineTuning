##Fine Tuning Tiny-Llama using LoRA


In this project, I fine tuned a [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) for [OpenAI gsm8k](https://github.com/openai/grade-school-math)
dataset, which is a high school mathematical question answer dataset, involvnig multiple reasoning steps. Chat models usually struggle on such problems.
