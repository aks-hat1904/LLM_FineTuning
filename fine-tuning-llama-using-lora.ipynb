{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n\nfrom peft import LoraConfig, get_peft_model, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T16:35:52.883286Z","iopub.execute_input":"2025-07-02T16:35:52.883550Z","iopub.status.idle":"2025-07-02T16:36:01.294403Z","shell.execute_reply.started":"2025-07-02T16:35:52.883530Z","shell.execute_reply":"2025-07-02T16:36:01.293796Z"}},"outputs":[{"name":"stderr","text":"2025-07-02 16:35:58.352607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751474158.375122     104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751474158.381995     104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T16:31:55.535724Z","iopub.execute_input":"2025-07-02T16:31:55.536371Z","iopub.status.idle":"2025-07-02T16:33:17.622536Z","shell.execute_reply.started":"2025-07-02T16:31:55.536348Z","shell.execute_reply":"2025-07-02T16:33:17.621664Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed bitsandbytes-0.46.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"model_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_compute_dtype = torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config = bnb_config,\n    device_map = 'cuda:0',\n    trust_remote_code = True\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:14.060017Z","iopub.execute_input":"2025-07-02T17:36:14.060570Z","iopub.status.idle":"2025-07-02T17:36:16.932698Z","shell.execute_reply.started":"2025-07-02T17:36:14.060546Z","shell.execute_reply":"2025-07-02T17:36:16.932084Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=['q_proj', 'v_proj'],\n    lora_dropout = 0.05,\n    bias = 'none',\n    task_type=TaskType.CAUSAL_LM\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:20.724722Z","iopub.execute_input":"2025-07-02T17:36:20.724964Z","iopub.status.idle":"2025-07-02T17:36:20.788404Z","shell.execute_reply.started":"2025-07-02T17:36:20.724947Z","shell.execute_reply":"2025-07-02T17:36:20.787856Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data = load_dataset('openai/gsm8k', 'main', split='train[:200]')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:22.971235Z","iopub.execute_input":"2025-07-02T17:36:22.971537Z","iopub.status.idle":"2025-07-02T17:36:23.918321Z","shell.execute_reply.started":"2025-07-02T17:36:22.971518Z","shell.execute_reply":"2025-07-02T17:36:23.917477Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def tokenize(batch):\n    texts = [\n        f\"### Instruction:\\n{instruction}\\n### Response:\\n{out}\"\n        for instruction, out in zip(batch['question'], batch['answer'])\n    ]\n\n    tokens = tokenizer(\n        texts,\n        padding = 'max_length',\n        max_length = 256,\n        truncation = True,\n        return_tensors = 'pt'\n    )\n\n    tokens['labels'] = tokens['input_ids'].clone()\n\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:34.648516Z","iopub.execute_input":"2025-07-02T17:36:34.649369Z","iopub.status.idle":"2025-07-02T17:36:34.653851Z","shell.execute_reply.started":"2025-07-02T17:36:34.649341Z","shell.execute_reply":"2025-07-02T17:36:34.653059Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_data = data.map(tokenize, batched=True, remove_columns=data.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:38.189911Z","iopub.execute_input":"2025-07-02T17:36:38.190197Z","iopub.status.idle":"2025-07-02T17:36:38.225555Z","shell.execute_reply.started":"2025-07-02T17:36:38.190175Z","shell.execute_reply":"2025-07-02T17:36:38.224953Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir = './tinyllama-math-lora-tutorial',\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    learning_rate = 1e-3,\n    num_train_epochs = 50,\n    fp16 = True,\n    logging_steps = 20,\n    save_strategy = 'epoch',\n    report_to = 'none',\n    remove_unused_columns = False,\n    label_names = ['labels'] \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:41.957248Z","iopub.execute_input":"2025-07-02T17:36:41.957818Z","iopub.status.idle":"2025-07-02T17:36:41.989109Z","shell.execute_reply.started":"2025-07-02T17:36:41.957799Z","shell.execute_reply":"2025-07-02T17:36:41.988555Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_data,\n    processing_class = tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:46.754100Z","iopub.execute_input":"2025-07-02T17:36:46.754850Z","iopub.status.idle":"2025-07-02T17:36:46.765529Z","shell.execute_reply.started":"2025-07-02T17:36:46.754823Z","shell.execute_reply":"2025-07-02T17:36:46.764914Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T17:36:49.868019Z","iopub.execute_input":"2025-07-02T17:36:49.868766Z","iopub.status.idle":"2025-07-02T18:17:45.199992Z","shell.execute_reply.started":"2025-07-02T17:36:49.868741Z","shell.execute_reply":"2025-07-02T18:17:45.199435Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 40:44, Epoch 42/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.841700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.386200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.354300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.307800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.272300</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.237100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.199900</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.170100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.149900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.126300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.105800</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.096200</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.083700</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.078800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.072800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=300, training_loss=0.23219833294550576, metrics={'train_runtime': 2454.8709, 'train_samples_per_second': 4.074, 'train_steps_per_second': 0.122, 'total_flos': 1.3667648151748608e+16, 'train_loss': 0.23219833294550576, 'epoch': 42.96})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model.save_pretrained('./tinyllama-lora-tuned-adapter-math')\ntokenizer.save_pretrained('./tinyllama-lora-tuned-adapter-math')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:25:19.076015Z","iopub.execute_input":"2025-07-02T18:25:19.076606Z","iopub.status.idle":"2025-07-02T18:25:19.382099Z","shell.execute_reply.started":"2025-07-02T18:25:19.076583Z","shell.execute_reply":"2025-07-02T18:25:19.381449Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('./tinyllama-lora-tuned-adapter-math/tokenizer_config.json',\n './tinyllama-lora-tuned-adapter-math/special_tokens_map.json',\n './tinyllama-lora-tuned-adapter-math/tokenizer.model',\n './tinyllama-lora-tuned-adapter-math/added_tokens.json',\n './tinyllama-lora-tuned-adapter-math/tokenizer.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"**Evaluation of our fine-tuned model**\n\nNow we will compare our fine-tuned model with the base model, first using the data it was trained one, and then new but similar data","metadata":{}},{"cell_type":"code","source":"import os\nimport math\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom datasets import load_dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n\nfrom peft import PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:43:12.544435Z","iopub.execute_input":"2025-07-02T18:43:12.545194Z","iopub.status.idle":"2025-07-02T18:43:12.549784Z","shell.execute_reply.started":"2025-07-02T18:43:12.545170Z","shell.execute_reply":"2025-07-02T18:43:12.548843Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#model name will be the same as before\nmodel_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\nadapter_path = './tinyllama-lora-tuned-adapter-math/'\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_compute_dtype = torch.bfloat16\n) \n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config = bnb_config,\n    device_map = 'cuda:0',\n    trust_remote_code = True\n).eval()\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\ntmp_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config = bnb_config,\n    device_map = 'cuda:0',\n    trust_remote_code = True\n)\n\ntuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\ntuned_model = tuned_model.merge_and_unload().eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:51:25.744996Z","iopub.execute_input":"2025-07-02T18:51:25.745574Z","iopub.status.idle":"2025-07-02T18:51:30.526006Z","shell.execute_reply.started":"2025-07-02T18:51:25.745552Z","shell.execute_reply":"2025-07-02T18:51:30.525173Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def tokenize(batch):\n    texts = [\n        f\"### Instruction:\\n{instruction}\\n### Response:\\n{out}\"\n        for instruction, out in zip(batch['question'], batch['answer'])\n    ]\n\n    tokens = tokenizer(\n        texts,\n        padding = 'max_length',\n        max_length = 256,\n        truncation = True,\n        return_tensors = 'pt'\n    )\n\n    tokens['labels'] = tokens['input_ids'].clone()\n\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:52:30.102279Z","iopub.execute_input":"2025-07-02T18:52:30.102830Z","iopub.status.idle":"2025-07-02T18:52:30.107126Z","shell.execute_reply.started":"2025-07-02T18:52:30.102808Z","shell.execute_reply":"2025-07-02T18:52:30.106346Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"eval_data = load_dataset('openai/gsm8k', 'main', split='train[200:400]')\neval_data = eval_data.map(tokenize, batched=True, remove_columns=['question', 'answer'])\neval_data = eval_data.with_format('torch')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:20:08.004175Z","iopub.execute_input":"2025-07-02T19:20:08.004706Z","iopub.status.idle":"2025-07-02T19:20:09.032485Z","shell.execute_reply.started":"2025-07-02T19:20:08.004684Z","shell.execute_reply":"2025-07-02T19:20:09.031659Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cd40fbf22fe4cb3b85234c9b3f7a8be"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"eval_loader = DataLoader(\n    eval_data,\n    batch_size=8,\n    collate_fn = default_data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:20:14.281705Z","iopub.execute_input":"2025-07-02T19:20:14.282378Z","iopub.status.idle":"2025-07-02T19:20:14.286191Z","shell.execute_reply.started":"2025-07-02T19:20:14.282354Z","shell.execute_reply":"2025-07-02T19:20:14.285377Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"@torch.no_grad()\ndef compute_perplexity(model):\n    losses = []\n    for batch in eval_loader:\n        batch = {k: v.to('cuda') for k, v in batch.items()}\n        loss = model(**batch).loss\n        losses.append(loss.item())\n\n    return math.exp(sum(losses) / len(losses))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:20:37.630833Z","iopub.execute_input":"2025-07-02T19:20:37.631449Z","iopub.status.idle":"2025-07-02T19:20:37.635985Z","shell.execute_reply.started":"2025-07-02T19:20:37.631426Z","shell.execute_reply":"2025-07-02T19:20:37.635214Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\nprint(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:20:39.266505Z","iopub.execute_input":"2025-07-02T19:20:39.267158Z","iopub.status.idle":"2025-07-02T19:22:19.061318Z","shell.execute_reply.started":"2025-07-02T19:20:39.267134Z","shell.execute_reply":"2025-07-02T19:22:19.060504Z"}},"outputs":[{"name":"stdout","text":"Base Model Perplexity: 226.83\nTuned Model Perplexity: 4.78\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import random \nraw_data = load_dataset('openai/gsm8k', 'main', split='train[200:400]')\nrefs = raw_data['answer']\n\ndef generate(model, instruction):\n    token_ids = tokenizer(f'### instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n\n    with torch.no_grad():\n        out = model.generate(token_ids, max_new_tokens=256)\n\n    return tokenizer.decode(out[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:27:41.842833Z","iopub.execute_input":"2025-07-02T19:27:41.843247Z","iopub.status.idle":"2025-07-02T19:27:42.753098Z","shell.execute_reply.started":"2025-07-02T19:27:41.843218Z","shell.execute_reply":"2025-07-02T19:27:42.752511Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"raw_data['question'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:27:47.200166Z","iopub.execute_input":"2025-07-02T19:27:47.200847Z","iopub.status.idle":"2025-07-02T19:27:47.205858Z","shell.execute_reply.started":"2025-07-02T19:27:47.200827Z","shell.execute_reply":"2025-07-02T19:27:47.205305Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"refs[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:27:55.761195Z","iopub.execute_input":"2025-07-02T19:27:55.761476Z","iopub.status.idle":"2025-07-02T19:27:55.766424Z","shell.execute_reply.started":"2025-07-02T19:27:55.761457Z","shell.execute_reply":"2025-07-02T19:27:55.765803Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'Sansa earns $5 x 3 = $<<5*3=15>>15 every day by selling three 8-inch portraits.\\nThe price of the 16-inch portrait is $5 x 2 = $<<5*2=10>>10 each.\\nSo, she earns $10 x 5 = $<<10*5=50>>50 every day by selling five 16-inch portraits.\\nHer total earnings is $50 + $15 = $<<50+15=65>>65 every day.\\nTherefore, the total amount she earns after 3 days is $65 x 3 = $<<65*3=195>>195.\\n#### 195'"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"print(generate(base_model, raw_data['question'][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:28:08.641124Z","iopub.execute_input":"2025-07-02T19:28:08.641374Z","iopub.status.idle":"2025-07-02T19:28:13.106121Z","shell.execute_reply.started":"2025-07-02T19:28:08.641359Z","shell.execute_reply":"2025-07-02T19:28:13.105238Z"}},"outputs":[{"name":"stdout","text":"### instruction:\nSansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n### Response:\nSansa earns $100 per day, which means she earns $300 per week, and $500 per month. She sells 10 portraits per week, which means she earns $500 per week. She sells 20 portraits per month, which means she earns $1000 per month. She sells 30 portraits per year, which means she earns $3000 per year.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"print(generate(tuned_model, raw_data['question'][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T19:28:23.601501Z","iopub.execute_input":"2025-07-02T19:28:23.602072Z","iopub.status.idle":"2025-07-02T19:28:33.962487Z","shell.execute_reply.started":"2025-07-02T19:28:23.602025Z","shell.execute_reply":"2025-07-02T19:28:33.961782Z"}},"outputs":[{"name":"stdout","text":"### instruction:\nSansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n### Response:\nTo sell an 8-inch portrait for $5, Sansa earns it 1 time per day for 3 days a week.\nTo sell a 16-inch portrait for twice the price of the 8-inch portrait, Sansa earns it 4 times per day for 3 days a week.\nIf Sansa sells 3 portraits each day for 5 days a week, and she earns each portrait $5, she earns an average of $3.50 from selling portraits per day.\nThat means she earns $3.50 * 5 portraits per day * 3 days a week * 3 days a week * 5 days a week = $180.00 per week.\nIf she sells and earns each portrait eight times a day for 3 days a week, she earns it 8 times per day for 3 days a week, and she sells 5 portraits per day for 3 days a week, she earns an average of $5.00 from selling portraits per day.\nThat means she earns $5.00 * 5 portra\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}